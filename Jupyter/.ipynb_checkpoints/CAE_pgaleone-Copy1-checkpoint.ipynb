{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Autoencoders --CAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAE learn the filters that recontructs the input keeping the error at a minimum.\n",
    "These filters are able to extract features of the input that are used for the reconstruction.\n",
    "##### Autoencoder vs. Convolutional Autoencoder\n",
    "\n",
    "###### CAE\n",
    "Number of parameters required to produce an activation map is always the same, while the input size can vary. -> General Purpose feature extractor\n",
    "##### AE\n",
    "Input size must be the same as network size.\n",
    "Ingnores 2D structure of input. -> Input must be vektorized (1,x)\n",
    "AE's introduce redundancy in teh parameters, forcing each feature to be global\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution\n",
    "$f(t)*g(t) = \\int^{-\\infty}_{\\infty}{f(\\tau)g(t-\\tau)}$ 1D analytical\n",
    "\n",
    "$O(i,j) = \\sum^{\\infty}_{u=-\\infty}\\sum^{\\infty}_{v=-\\infty}{F(u,v)I(i-u,j-v)}$ 2D discrete space\n",
    "\n",
    "$O(i,j)=\\sum^{D}_{d=1}\\sum^{2k+1}_{u=-2k-1}\\sum^{2k+1}_{v=-2k-1}{F_{d}(u,v)I_{d}(i-u,j-v)}$ 3D image domain\n",
    "\n",
    "with $\\textbf{O(i,j)}$ the output pixel at $\\textbf(i,j)$\n",
    "\n",
    "and $\\textbf{2k+1}$ the the side of a square, odd filter\n",
    "\n",
    "and $\\textbf{F}$ the convolutional Filter\n",
    "\n",
    "and $\\textbf{I}$ the input image\n",
    "\n",
    "$\\textbf{O(i,j)}$ of the 3D convolution is also called the activation map\n",
    "\n",
    "After one convolution over the whole image domain (e.g square image domain $I_{w}=I_{h}$) with a square odd filter (2k+1) the output dimension becomes:\n",
    "\n",
    "$O_{w}=O{h}=\\frac{I_{w}-(2k+1)}{S}+1$\n",
    "\n",
    "with $\\textbf{S}$ beeing the stride size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode\n",
    " One convolution of an input volume $I = \\{I_{1},\\dots, I_{D}\\}$ with a set of n convolutional filters $\\{F_{1}^{1},\\dots,F_{n}^{1}\\}$ each with depth D, outputs n activation maps (activaion volume of depth n).\n",
    " \n",
    " $O_{m}(i,j)=a\\left(\\sum^{D}_{d=1}\\sum^{2k+1}_{u=-2k-1}\\sum^{2k+1}_{v=-2k-1}{F_{d}(u,v)I_{d}(i-u,j-v)}\\right)$ $m = 1, \\dots, n$\n",
    " \n",
    "Every convolution is wrapped by a non-linear function $\\textbf{a}$ (activation function) and weighted with a bias $b_{m}^{1}$.\n",
    "\n",
    "$z_{m}=O_{m}=a(I*F_{m}^{1}+b_{m}^{1})$ $m=1,\\dots,n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode\n",
    "The decoding, or transposed convolution is then givon by:\n",
    "\n",
    "$\\tilde{I}= a(Z*F_{m}^{2}+b_{m}^{2})$\n",
    "\n",
    "where $Z=\\{z_{i}\\}$  $i = 1,..,n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss\n",
    "For example the mean square error:\n",
    "$L(I,\\tilde{I}) = 0.5 ||I-\\tilde{I}||_{2}^{2}$\n",
    "\n",
    "Source: pgaleone.eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
