% !TEX root = master.tex

\chapter{Results}
\label{Ch:Results}
%\pagenumbering{arabic}
This chapter covers the evaluation of reconstructions \(\tilde{f}\) obtained from the FCNNs and the CNN through a comparison against reconstructions obtained from POD. Additionally, an analysis of the interpretability of the intrinsic variables \(\idhy\) and \(\idrare\) is provided. This chapter concludes with the attempt to create new states of the FOM with the FCNN, which can be viewed as an online phase of MOR.\\ 
The benchmarking of POD and neural networks begins with a contrast of the number of parameters to obtain \(\tilde{f}\). Beforehand, solely the number of trainable parameters that compose both neural networks were called \(\frepar\). For this comparison, \(\frepar\) is extended and includes all elements of the left and right singular vectors as well as the singular values of POD. Additionally, the amount of intrinsic variables used for reconstruction is set to \(p=3\) and \(p=5\) for \(\hy\) and \(\rare\) respectively. An exception is the CNN which uses \(p=5\) independently from rarefaction level. A summary is provided in \cref{Tab: Parameters}.\\   
\begin{table}[htp]
	\centering
	\caption{Amount of parameters \(\frepar\) used to reconstruct \(f\), the number of intrinsic variables \(p\) and the corresponding $\L2$-Error for POD, the FCNNs, and the CNN.}
	\begin{tabular*}{16cm}{ @{\extracolsep{\fill}} c c c c c c c @{} }
		\toprule
		Algorithm & \multicolumn{2}{c}{Parameters \(\frepar\)} & \multicolumn{2}{c}{Int. variables \(p\)}& \multicolumn{2}{c}{$\L2$-Error} \\ [.5ex]
		 & \(\hy\)&\(\rare\)&\(\hy\)&\(\rare\)&\(\hy\)&\(\rare\)\\   
		\hline
		POD     & 15129 & 25225 & 3 & 5 & 0.0205 & 0.0087 \\
		FCNN 	& 2683 & 3725 & 3 & 5 & 0.0008 & 0.0009 \\
		CNN   	& 8246 & 8246 & 5 & 5 &	0.025 & 0.027\\
		\bottomrule
	\end{tabular*} \label{Tab: Parameters}
\end{table}
POD uses 15129 and 25225 parameters to reconstruct \(\hy\) and \(\rare\) respectively. This is the largest amount of parameters of all three algorithms, which yield \(\L2\)-errors of 0.0205 and 0.0087 respectively. Interestingly, the elevation of \(p\) amounts to an increase of parameters by approximately 1.7, which is comparable to the FCNN with an approximate increase of 1.4. The FCNN, which holds the best \(\L2\)-errors of 0.0008 and 0.0009 for \(\hy\) and \(\rare\) respectively, does so with the least amount of parameters. For reconstructing \(\hy\) solely 2683 and for the reconstruction of \(\rare\) solely 3725 parameters are used, which is a fraction of the need for POD. The second most populous algorithm is the CNN, which uses 8246 parameters for both rarefaction levels. The resulting \(\L2\)-errors with 0.025 for \(\hy\) and 0.027 for \(\rare\) are the largest of all three algorithms. \\

Next, a qualitative analysis with actual reconstructions is presented. For this purpose the \(\L2\)-error over time \(t\), seen in \cref{Fig:ErrTime}, is used to localize the most challenging snapshot for each algorithm.\\ 
\begin{figure}[tp!]
	\input{Figures/Chapter_5/ErrTime.tex}
	\caption{\(\L2\)-error over time for POD, the FCNNs, and the CNN. Results for $\hy$ are displayed on the left, the results for $\rare$ are displayed on the right.}
	\label{Fig:ErrTime}
\end{figure}
With POD and the CNN the last timestep, at $t=0.12s$, for both rarefaction levels is the most rich in the $L2$-Error. In contrast, the FCNN does not show a distinct time dependence of the \(\L2\)-error. Nonetheless, struggles at the onset at around $t=0.005s$ with $\hy$ and around \(t=0.005s\) and \(t=0.0115\) (in the beginning and at the end) with $\rare$ can be observed for the FCNN. Examples of reconstructions $\tilde{f}(x,v,t_i)$ with $t_i=0.12s$ and $x \in [0.375,0.75]$ are given in \cref{Fig: ErrWorst}.\\
\begin{figure}[tp!]
	\input{Figures/Chapter_5/ErrWorst.tex}
	\caption{Comparison of the FOM solutions \(f\) with three reconstructions \(\tilde{f}\) obtained from POD, the FCNNs and the CNN. Reconstrucions are shown at \(t=0.12s\) for \(x\in [0.375,0.75]\). The top row displays case $\hy$, bottom row displays case $\rare$. The colobars reference \(f\) and \(\tilde{f}\).}
	\label{Fig: ErrWorst}
\end{figure}
The FOM solution viewed as $f(x,v,t_i)$ has been introduced in \cref{Ch:BGK}. There, $f(x_j,v,t_i)$ is the probability distribution of the microscopic velocities $v$ at point $x_j$ in space at one moment $t_i$ in time for a gas.
With this in mind, a qualitative comparison between the three algorithms is made, considering the rendition of the velocity probabilities. Starting with \(\hy\), seen in the top row of \cref{Fig: ErrWorst} it can be observed that \(\tilde{f}(x,v,t_i)\) starting around \(x=0.6\) gets defective for POD and the CNN. Noteworthy, here the probability distribution is thinner than the original with POD. This in turn leads to errors in the temperature \(T\) once passing \(x\approx 0.6\). Prominent qualitative deviations using the CNN are especially blurriness/pixelation of \(\tilde{f}(x,v,t_i)\) after \(x\approx 0.6\). In contrast, the FCNN seems to reproduce the FOM solution almost exactly.\\
Continuing with a row further down in \cref{Fig: ErrWorst} and therefore with \(\rare\). The FCNN seems to reproduce the FOM solution without any visible drawback. POD also seems to reproduce all important structures, except after \(x\approx 0.7\) around the contact discontinuity, some values for velocities with \(v>0\) appear to be missing. Again, the CNN struggles with blurriness making \(\tilde{f}\) for both rarefaction levels look largely similar.      
\begin{figure}[H]
	\input{Figures/Chapter_5/MacroError.tex}
	\caption{Matching of macroscopic quantities \(\rho\), \(\rho u\) and \(E\) reproduced by POD, the FCNNs the and CNN with macroscopic quantities computed from the FOM. Top row shows results for \(\hy\), bottom row for \(\rare\) at time \(t_i=0.12s\). The CNN is displayed with marks only because of trembles in the signal.}
	\label{Fig:ErrMacro}
\end{figure}
Loss of information described above can unfold in severe mistakes in \(\rho\), \(\rho u\) and \(E\), the macroscopic quantities, as displayed in \cref{Fig:ErrMacro}. Examining the macroscopic quantities enables a detailed look at the reconstruction errors. Features of the macroscopic quantities are discussed in terms of rarefaction wave, contact discontinuity, and height as well as the position of the shockfront. For a detailed elaboration of these terms see \cref{Ch:BGK}. Following the structure in the preceding figures, macroscopic quantities of \(\hy\) are displayed in the top row and for \(\rare\) in the bottom row of \cref{Fig:ErrMacro}. Firstly, the reproduction of the macroscopic quantities \(\rho\), and \(\rho u\)  obtained by the FCNN match the FOM solution exact for both levels of rarefaction \(\hy\) and \(\rare\). Interestingly, despite the overall impressive performance of the FCNN regarding the small number of parameters it uses, the total energy shows small deviations around the tail of the rarefaction wave for \(\hy\) and somewhat severe errors at the transition from rarefaction wave to shock front for \(\rare\). Secondly, the CNN produces trembles in \(\rho u\) and especially in \(E\) which is why it's shown with marks only. The macroscopic quantities reproduced by the CNN show, its inability to differentiate between \(\hy\) and \(\rare\). Specifically, the macroscopic quantities for \(\rare\) appear to be a copy of the ones for \(\hy\). Additionally, considering \(\hy\), it can be observed, that the momentum \(\rho u\) holds small errors for the tail of the rarefaction wave as well as the contact discontinuity. The value for the tip of the shockwave exceeds, comparable with POD, the exact solution. Thirdly POD performs better on \(\rare\), which is unsurprising considering the difference in the number of used parameters, holding only small deviations of the contact discontinuity and the shockwave for the momentum \(\rho u\) and the total energy \(E\). The density \(\rho\) matches the FOM solution exact. Pronounced deviations from the FOM solution occur using POD on \(\hy\). The density \(\rho\) undercuts the original shockwave. The momentum \(\rho u\) heavily exceeds the tail of the rarefaction wave and to the same extent undercuts the contact discontinuity. Thus, in the total energy \(E\), the same is observable for the tail of the rarefaction wave and the contact discontinuity.
\begin{figure}[H]
	\input{Figures/Chapter_5/Conservation.tex}
	\caption{Comparison of the conservative properties of reconstructions obtained from POD, the FCNNs, and the CNN against the conservative properties of the FOM solution using the temporal mean.}
	\label{Fig:Conservation}
\end{figure}
The physical consistency of \(\tilde{f}\), in terms of conservation of mass momentum and energy, is a critical criterion for its validity. Hence, conservation properties are analyzed in the following. In that respect, the temporal mean over the time derivative, which can be calculated exemplary for \(\rho\) with
\begin{equation}
	\frac{\mathrm{d}}{\mathrm{d}t}\int \rho(x,t)\, \mathrm{d}x\Delta t  =\overline{\dot{\rho}}\mathrm{,}
\end{equation}
of the macroscopic quantities is employed. \Cref{Fig:Conservation} shows the conservation of mass, momentum, and total energy as a temporal mean for \(\hy\) in the top row and \(\rare\) in the bottom row.\\
Conservation of mass is met using the FCNN, except for small deviations at the outset for both cases \(\hy\) and \(\rare\). Similarly, POD meets conservation of mass for \(\rare\). The erroneous \(\hy\) case losses mass at the onset and gains mass towards the end with POD. Conservation of momentum meets the FOM solution, except for minor gains and loses, after \(t\approx 0.03s\) using the FCNN for both cases \(\hy\) and \(\rare\). POD gains momentum of 0.13 for \(\hy\) and 0.07 for \(\rare\). The conservation of total energy is met for \(\hy\) and \(\rare\) using POD and the FCNN. Finally, the reconstructions of the CNN do not conserve mass, momentum nor total energy. All conservative properties behave comparable to a sawtooth wave. A gain and loss of either of the quantities can be observed.\\

Because of the black-box nature of neural networks, the question of interpretability often arises when working with them \cite{fan2021interpretability}. Especially benchmarking neural networks for model order reduction with POD asks for evaluating the interpretability of the intrinsic variables. Owing to the tremendous quality of POD, which lies in "the physically interpretable decomposition"\cite{Kutz}[p.375] of the input data, as stated in \cref{Ch:DimRedAl}.\\
Following the deduction, that \(\hy\) can be completely described in terms of three macroscopic quantities and that \(\rare\) is describable in a similar way, it is put to test if the intrinsic variables \(\idhy\) and \(\idrare\) show any similarities, if not match any macroscopic quantity. To this end, two supplementary macroscopic quantities, namely the temperature \(T\) and macroscopic velocity \(u\), are added to the three macroscopic variables. In \cref{Fig: Macro_hy} and \cref{Fig: Macro_rare}, these are depicted first over the whole domain of \(x\) and \(t\) and for two specific timesteps \(t=0.055s\) and \(t=0.12s\) for \(\hy\) and \(\rare\) respectively. Similarily are the intrinsic variables \(\idhy\) and \(\idrare\) with\\\\
\begin{minipage}{0.45\textwidth}
	\begin{equation}
		[h_0(x,t),\dots,h_p(x,t)] = \idhy
	\end{equation}
\end{minipage}%
\begin{minipage}{0.45\textwidth}
	\begin{equation}
		\mathrm{and}\quad[r_0(x,t),\dots,r_p(x,t)] = \idrare
	\end{equation}
\end{minipage},\\\\\
depicted in \cref{Fig: Code_hy} and \cref{Fig: Code_rare} respectively.\\
Strikingly, most intrinsic variables appear to be a sort of linear combination of the five intrinsic variables. In particular \(\idhy\). For example, the rarefaction wave, shock wave, and contact discontinuity, which can be identified in \(h_0\) reflect a combination of those found in the density \(\rho\) and the total energy \(E\). Furthermore, \(h_1\) seems to be a mirror image of the momentum \(\rho u\), where beginning end values are inspired by the temperature \(T\). Then again, \(T\) plays a more pronounced role in \(h_2\), where its fluctuation appears. The peak of \(h_2\) could be guessed from the peak of the macroscopic velocity \(u\) with its bump at \(t=0.12\).\\
A clear identification of macroscopic quantities that can be seen in \(\idrare\) is possible for \(r_3\), which reflects the shape of the density \(\rho\). Moreover, the peak of the velocity \(u\) can be rediscovered in the through of \(r_0\). For other intrinsic variables of \(\idrare\) namely \(r_1\), \(r_2\) and \(r_3\) a clear discernability of macroscopic quantities is not observed. It seems rather that those constitute abstract information about the rarefied flow. Nonetheless, it can't be verified, that their creation through linear combinations is impossible.
\clearpage
\begin{figure}[htp!]
	\input{Figures/Chapter_5/fom_mac_hy.tex}
	\caption{Macroscopic quantities of \(\hy\). Density \(\rho\), momentum \(\rho u\), total energy \(E\), teperature \(T\) and velocity \(u\) over time \(t\) and space \(x\) in the top row and specifically at \(t_i=0.055s\) and \(t_i=0.12\) in the middle and bottom row respectively.}
	\label{Fig: Macro_hy}
\end{figure}
\begin{figure}[hbp!]
	\input{Figures/Chapter_5/fom_mac_rare.tex}
		\caption{Macroscopic quantities of \(\rare\). Density \(\rho\), momentum \(\rho u\), total energy \(E\), teperature \(T\) and velocity \(u\) over time \(t\) and space \(x\) in the top row and specifically at \(t_i=0.055s\) and \(t_i=0.12\) in the middle and bottom row respectively.}
	\label{Fig: Macro_rare}
\end{figure}
\clearpage
\begin{figure}[htp!]
	\centering
	\input{Figures/Chapter_5/code_hydro.tex}
	\caption{Intrinsic variables \(h_0(x,t)\), \(h_1(x,t)\) and \(h_2(x,t)\) of \(\idhy\) obtained from the FCNN. Top row depicts \(\idhy\) over the whole \((x,t)\) domain, middle and bottom row for \(t=0.055\) and \(t=0.12\) respectively.}
	\label{Fig: Code_hy}
\end{figure}
\begin{figure}[hbp!]
	\input{Figures/Chapter_5/code_rare.tex}
	\caption{Intrinsic variables \(r_0(x,t)\), \(r_1(x,t)\), \(r_2(x,t)\), \(r_3(x,t)\) and \(r_4(x,t)\) of \(\idrare\) obtained from the FCNN. Top row depicts \(\idrare\) over the whole \((x,t)\) domain, middle and bottom row for \(t=0.055\) and \(t=0.12\) respectively.}
	\label{Fig: Code_rare}
\end{figure}
\clearpage
The intrinsic variables extracted from the CNN and POD are shown in \cref{Fig: CNNPOD}. They are only dependent on \(v\) with\\
\begin{minipage}{0.45\textwidth}
	\begin{equation}
	[h_1(v),\dots,h_p(v)] = \idhy
	\end{equation}
\end{minipage}%
\begin{minipage}{0.45\textwidth}
	\begin{equation}
	\mathrm{and}\quad[r_n(v),\dots,r_p(v)] = \idrare
	\end{equation}
\end{minipage}.\\\\\
The third and fourth row of \cref{Fig: CNNPOD} show the first three and five POD modes of \(\hy\) and \(\rare\) respectively. As expected, the first three modes of both rarefaction levels do not differ significantly. Equally, the bulk dynamic answer of the two gas flows to the test case doesn't. Pronounced differences of \(\idhy\) and \(\idrare\) extracted from the CNN, seen in the first and second row of \cref{Fig: CNNPOD}, are also not observed. This aligns with previous findings that the CNN fails to differentiate between \(\hy\) and \(\rare\). Qualitatively, the intrinsic variables of the CNN show less complexity compared to those of POD. Nonetheless, a rough analogy between the two can be observed. Especially \(h_0\) and \(r_0\), the first intrinsic variables of the CNN, resemble those of POD. Furthermore, a small through in \(h_1\) and \(r_1\) of the CNN can be identified. This through, though much more pronounced, is also present in \(h_1\) and \(r_1\) of POD. Worth mentioning is that \(h_0\) and \(r_0\), \(h_1\) and \(r_1\) as well as \(h_4\) and \(r_4\) of the CNN encompass the largest peaking of all intrinsic variables.\\    
\begin{figure}[hp!]
	\input{Figures/Chapter_5/code_cnn_pod.tex}
	\caption{Intrinsic variables \(h_0(v)\), \(h_1(v)\), \(h_2(v)\), \(h_3(v)\) and \(h_4(v)\) of \(\idhy\) in the top row and \(r_0(v)\), \(r_1(v)\), \(r_2(v)\), \(r_3(v)\) and \(r_4(v)\) of \(\idrare\) of in the second row extracted from the CNN. Third and fourth row show \(h_0(v)\), \(h_1(v)\), \(h_2(v)\) of \(\idhy\) and \(r_0(v)\), \(r_1(v)\) , \(r_2(v)\), \(r_3(v)\) and \(r_4(v)\) of \(\idrare\) extracted from POD respectively.}
	\label{Fig: CNNPOD}
\end{figure}

Usually, POD within a Galerkin framework exploits the intrinsic variables as in \cite{Bernard} to produce new states. The same is possible with the intrinsic variables obtained from autoencoders as in \cite{Carlberg}. Both won't be discussed in this contribution. Rather, new states are obtained by performing an interpolation in time \(t\) of \(\idhy\) and \(\idrare\). This approach tests a different kind of ability to generalize about the FOM solution. So far there have been two kinds of generalization tested: The first can be encountered during training, where a split into train- and validation set, probes the ability to fit unseen examples. A second approach to generalization is tried with the CNN, where both rarefaction levels as training examples probe the ability to fit both in the same model. The third insight into the ability to generalize is tested using the FCNN. By the temporal interpolation in the intrinsic variables, it is probed if new states can be generated that meet the condition of MOR that the distance \(||f - \tilde{f}||\) is small.\\
For this thesis, an additional solution \(\hy^*\) of the BGK model in Sod's shock tube with \(\Kn=0.00001\) is provided with a temporal resolution of 241 snapshots. This resolution is 9.64 times finer than the original one. Hence, an interpolation using cubic splines in the temporal axis of \(\idhy\) is performed, thus resulting in intrinsic variables called \(\idhy^*\). The temporal resolution \(\idhy^*\) is as well 241  and fed into the decoder of the FCNN generating \(\widetilde{\hy}^*\). A comparison of \(\hy^*\) against \(\widetilde{\hy}^*\) as truth against prediction in terms of macroscopic quantities density \(\rho\), momentum \(\rho u\) and total energy \(E\) is provided in \cref{Fig: IntHy}.
\begin{figure}[H]
	\input{Figures/Chapter_5/Hy_Int.tex}
	\caption{Macroscopic quantities density \(\rho\), momentum \(\rho u\) and total Energy \(E\), displayed in this order, at time \(t=0.12\) against predictions generated from interpolation. Temporal interpolation with cubic splines is performed in \(\idhy\) from 25 snapshots to 241 snapshots.}
	\label{Fig: IntHy}
\end{figure}
The generated snapshots match the macroscopic quantities almost exactly, similar to the results obtained without interpolation. Nonetheless, the resulting \(\L2\)-error for \(\widetilde{\hy}^*\) increases to \(\L2=0.0012\), which is 1.5 times higher than the original \(\L2\)-error.\\

In summary, the reconstructions obtained from the CNN do not meet conservation of mass, momentum, and total energy, which devalues their physical applicableness. Nonetheless, the CNN uses with 8246, the second-highest amount of parameters. The attempt to learn both levels of rarefaction with the CNN subsequently also failed. Specifically, the CNN reconstructs \(\hy\) from \(\rare\) as input. In addition, the intrinsic variables of the CNN show, to some degree, similarities to POD basis modes. \\
The FCNN uses with 2683 to 3725 parameters the least amount, while achieving the lowest \(\L2\)-error in the range of \num{8e-4} to \num{9e-4}. At the same time for \(\hy\), fewer parameters than for \(\rare\) are needed to achieve comparable results using the FCNN. Conservation of mass momentum and total energy is met, hence macroscopic quantities of considerable accuracy can be obtained which show a good fit to the FOM solution's. The question of the interpretability of the intrinsic variables is up to discussion owing to their entangled nature, especially for \(\rare\). Generalization was successfully tested, by generating new snapshots of \(\hy\) but at the same time increasing the \(\L2\)-error to \num{1.2e-3}.\\
Both neural networks are tested against POD. By fixing \(p\) the algorithm is artificially limited and performs under its abilities. However, POD uses with this adjustment five to six times more parameters than the FCNN. Its deterministic character enables POD to achieve any possible accuracy, which was not observed with the neural networks.    
\subsection{Discussion and Outlook}
An interesting finding during the hyperparameters search is the different number of parameters, that the FCNN requires to achieve comparable results for the slip- and the continuum flow. The continuum flow requires 1.4 times fewer parameters compared to the rarefied flow. To recap, a continuum flow can be described in terms of three macroscopic quantities, a rarefied flow is described as a probability distribution of the macroscopic velocities of all involved particles. In turn, the necessity of using more parameters for the rarefied flow arises. This can be interpreted as a validation of the FCNN, as physical properties are reflected.\\
POD and the FCNN have different qualities. With the setting described above, POD uses up to 6.7 times more parameters than the FCNN for the given reconstruction losses. This suggests, that the quality of the parameters, that the FCNN has learned surpasses those of POD. On the other hand, the FCNN shows to be limited in terms of reconstruction loss that can be achieved. Therefore, the applicability of either of the methods for MOR can eventually be decided by the use case. Whenever computational resources like available memory are scarce, then the FCNN would be the method of choice. In other cases where reconstruction loss needs to be below that of the FCNN and computational resources are not limited, POD would be the preferred method.\\
Why was the training of the CNN not successful, even though it could benefit from using more parameters compared to the FCNN? Convolutional layers comprise sparsity through local connectivity of nodes as explained in \cite{Goodfellow}. This in turn yields a regulative effect. Additionally, convolutional layers have more hyperparameters that can be tuned than fully connected layers. This can make it harder to find the right set of hyperparameters for convolutional neural networks. Furthermore, the CNN could feed on much fewer examples of the flows, considering 5000 examples for the FCNN versus 40 per flow for the CNN. This effect was tried to compensate through data augmentation methods but did not yield any improvement. Those three driving factors, the intrinsic regulative effect of convolutional layers, unfit hyperparameters, and data scarcity are thought to be responsible for the performance of the CNN.\\
These considerations raise the question of the optimality of hyperparameters for both neural networks. It is unknown if both neural networks reached an optimal local minimum of the cost function. Hence the continued search for hyperparameters is left to future works. For example, both neural networks are intentionally kept small enough to not overfit. Therefore, it is possible to raise the capacity of both networks and letting them intentionally overfit, to then use regularizing methods as e.g. weight decay or dropout, to decrease the generalization gap. Both methods enable for a flexible adjustment of capacity, that, to some extend, is learned by the network. An important hyperparameter, that has been left out during the hyperparameter search, is the loss function. Ultimately the loss function determines what is considered as a good solution and what is not. The binary cross-entropy loss with logits from \texttt{pyTorch} could be used as an alternative. Promising are also physically inspired considerations, like a loss function that includes the conservation of mass, momentum, and energy.\\
Furthermore, it is proposed, to test LSTM (long short term memory) cells or similar GRUs (gated recurrent units) in an encoder-decoder configuration against projection methods like the Galerkin projection, in evolving the intrinsic variables in time. Additionally, could the variational autoencoder (VAE) or the Wasserstein autoencoder (WAE) be used to generate disentangled intrinsic variables. In this regard, it is as well proposed to explore the possibility of the existence of a linear system of equations that entangles the intrinsic variables found in this thesis. 
Finally, methods from natural language translation like transformer models introduced to rarefied gas dynamics could be applied to translate flows of differing levels of rarefaction into each other.
 