\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{JHEP}
\@input{front/title.aux}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\babel@aux{english}{}
\babel@aux{english}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Contents}{i}{chapter*.1}\protected@file@percent }
\@input{chapters/introduction.aux}
\@input{chapters/BGK_model.aux}
\@input{chapters/Deep_Learning.aux}
\@input{chapters/Reduced_order_Modeling.aux}
\@input{chapters/Results.aux}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Hyperparameters for the Fully Connected Autoencoder}{38}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{Ch:ApA}{{A}{38}{Hyperparameters for the Fully Connected Autoencoder}{appendix.A}{}}
\newlabel{Ch:ApA@cref}{{[appendix][1][2147483647]A}{[1][38][]38}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Initial selection for batch size, bottleneck size, number of epochs, learning rate and applied activation functions.\relax }}{38}{table.caption.30}\protected@file@percent }
\newlabel{Tab:First Guess}{{A.1}{38}{Initial selection for batch size, bottleneck size, number of epochs, learning rate and applied activation functions.\relax }{table.caption.30}{}}
\newlabel{Tab:First Guess@cref}{{[table][1][2147483647,1]A.1}{[1][38][]38}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Results for the variation of depth. Given are minimum values of training and validation error as well as the \(\L 2\). The minima where reached around the last 50 epochs of the training.\relax }}{39}{table.caption.31}\protected@file@percent }
\newlabel{Tab:Depth}{{A.2}{39}{Results for the variation of depth. Given are minimum values of training and validation error as well as the \(\L 2\). The minima where reached around the last 50 epochs of the training.\relax }{table.caption.31}{}}
\newlabel{Tab:Depth@cref}{{[table][2][2147483647,1]A.2}{[1][38][]39}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Five experiments over the different depth with $\hy  $ left and $\rare  $ right. The number of layers used for every experiment are given. Training and validation loss are shown over 2000 epochs.\relax }}{40}{figure.caption.32}\protected@file@percent }
\newlabel{Fig:Depth}{{A.1}{40}{Five experiments over the different depth with $\hy $ left and $\rare $ right. The number of layers used for every experiment are given. Training and validation loss are shown over 2000 epochs.\relax }{figure.caption.32}{}}
\newlabel{Fig:Depth@cref}{{[figure][1][2147483647,1]A.1}{[1][39][]40}}
\citation{BGK}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Results for the variation of width. Given are minimum values of training and validation error as well as the \(\L 2\). The minima where reached around the last 50 epochs of the training.\relax }}{41}{table.caption.33}\protected@file@percent }
\newlabel{Tab:Width}{{A.3}{41}{Results for the variation of width. Given are minimum values of training and validation error as well as the \(\L 2\). The minima where reached around the last 50 epochs of the training.\relax }{table.caption.33}{}}
\newlabel{Tab:Width@cref}{{[table][3][2147483647,1]A.3}{[1][39][]41}}
\newlabel{Fig:Width}{{\caption@xref {Fig:Width}{ on input line 81}}{42}{Hyperparameters for the Fully Connected Autoencoder}{figure.caption.34}{}}
\newlabel{Fig:Width@cref}{{[appendix][1][2147483647]A}{[1][41][]42}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Five experiments over different width with $\hy  $ left and $\rare  $ right. The number of nodes used for every experiment are given. Training and validation loss are shown over 4000 epochs.\relax }}{42}{figure.caption.34}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Minimum values of training and validation error as well as the \(\L 2\) defined in \cref  {Ch:ROM}. The minima where reached around the last 50 epochs.\relax }}{43}{table.caption.35}\protected@file@percent }
\newlabel{Tab:Batch}{{A.4}{43}{Minimum values of training and validation error as well as the \(\L 2\) defined in \cref {Ch:ROM}. The minima where reached around the last 50 epochs.\relax }{table.caption.35}{}}
\newlabel{Tab:Batch@cref}{{[table][4][2147483647,1]A.4}{[1][41][]43}}
\@writefile{lot}{\contentsline {table}{\numberline {A.5}{\ignorespaces L2-Error different activation functions and combinations for $\hy  $.\relax }}{43}{table.caption.36}\protected@file@percent }
\newlabel{Tab:Activations Hydro}{{A.5}{43}{L2-Error different activation functions and combinations for $\hy $.\relax }{table.caption.36}{}}
\newlabel{Tab:Activations Hydro@cref}{{[table][5][2147483647,1]A.5}{[1][41][]43}}
\@writefile{lot}{\contentsline {table}{\numberline {A.6}{\ignorespaces L2-Error different activation functions and combinations for $\rare  $.\relax }}{43}{table.caption.37}\protected@file@percent }
\newlabel{Tab:Activations Rare}{{A.6}{43}{L2-Error different activation functions and combinations for $\rare $.\relax }{table.caption.37}{}}
\newlabel{Tab:Activations Rare@cref}{{[table][6][2147483647,1]A.6}{[1][41][]43}}
\@writefile{lot}{\contentsline {table}{\numberline {A.7}{\ignorespaces L2-Error different activation functions and combinations for $\hy  $.\relax }}{44}{table.caption.38}\protected@file@percent }
\newlabel{Tab:Activations Rare 2nd}{{A.7}{44}{L2-Error different activation functions and combinations for $\hy $.\relax }{table.caption.38}{}}
\newlabel{Tab:Activations Rare 2nd@cref}{{[table][7][2147483647,1]A.7}{[1][41][]44}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces Training with different mini-batch sizes for $\hy  $. Train -and test loss is shown over 5000 epochs.\relax }}{45}{figure.caption.39}\protected@file@percent }
\newlabel{}{{A.3}{45}{Training with different mini-batch sizes for $\hy $. Train -and test loss is shown over 5000 epochs.\relax }{figure.caption.39}{}}
\newlabel{@cref}{{[figure][3][2147483647,1]A.3}{[1][44][]45}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces Training with different mini-batch sizes for $\rare  $. Train -and test loss is shown over 5000 epochs.\relax }}{46}{figure.caption.40}\protected@file@percent }
\newlabel{}{{A.4}{46}{Training with different mini-batch sizes for $\rare $. Train -and test loss is shown over 5000 epochs.\relax }{figure.caption.40}{}}
\newlabel{@cref}{{[figure][4][2147483647,1]A.4}{[1][44][]46}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces balblabla\relax }}{47}{figure.caption.41}\protected@file@percent }
\newlabel{Fig:Activations Hydro 1}{{A.5}{47}{balblabla\relax }{figure.caption.41}{}}
\newlabel{Fig:Activations Hydro 1@cref}{{[figure][5][2147483647,1]A.5}{[1][44][]47}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces \relax }}{48}{figure.caption.42}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces blablabla\relax }}{49}{figure.caption.43}\protected@file@percent }
\newlabel{Fig:Activations Rare}{{A.6}{49}{blablabla\relax }{figure.caption.43}{}}
\newlabel{Fig:Activations Rare@cref}{{[figure][6][2147483647,1]A.6}{[1][44][]49}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces blablabla\relax }}{50}{figure.caption.44}\protected@file@percent }
\newlabel{}{{A.6}{50}{blablabla\relax }{figure.caption.44}{}}
\newlabel{@cref}{{[figure][6][2147483647,1]A.6}{[1][44][]50}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.7}{\ignorespaces blablabla\relax }}{51}{figure.caption.45}\protected@file@percent }
\newlabel{Fig:Activations Rare 2nd3rd}{{A.7}{51}{blablabla\relax }{figure.caption.45}{}}
\newlabel{Fig:Activations Rare 2nd3rd@cref}{{[figure][7][2147483647,1]A.7}{[1][44][]51}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Hyperparameters for the Convolutional Autoencoder}{52}{appendix.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{Ch:ApB}{{B}{52}{Hyperparameters for the Convolutional Autoencoder}{appendix.B}{}}
\newlabel{Ch:ApB@cref}{{[appendix][2][2147483647]B}{[1][52][]52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.0.1}Appendix B}{52}{subsection.B.0.1}\protected@file@percent }
\newlabel{Sec:AppendixA}{{B.0.1}{52}{Appendix B}{subsection.B.0.1}{}}
\newlabel{Sec:AppendixA@cref}{{[subsubappendix][1][2147483647,2,0]B.0.1}{[1][52][]52}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Three convolutional networks with differing depth and with identical kernel evolution for $\rare  $.\relax }}{53}{figure.caption.47}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces Different Channel sizes for three convolutional networks with differing depth for $\rare  $.\relax }}{54}{figure.caption.48}\protected@file@percent }
\bibdata{other/references}
\bibcite{BGK}{1}
\bibcite{Franz}{2}
\bibcite{Kutz}{3}
\bibcite{Bernard}{4}
\bibcite{Carlberg}{5}
\bibcite{Goodfellow}{6}
\bibcite{Rumelhart}{7}
\bibcite{Ballard}{8}
\bibcite{Rifai2011}{9}
\bibcite{Rifai_2011a}{10}
\bibcite{rifai2012generative}{11}
\bibcite{schaaf}{12}
\bibcite{puppo2019kinetic}{13}
\bibcite{Sod}{14}
\bibcite{CFD1}{15}
\bibcite{LeCun98}{16}
\bibcite{he2015}{17}
\bibcite{torch_ini}{18}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{55}{appendix*.49}\protected@file@percent }
\bibcite{bushaev_2017}{19}
\bibcite{kingma2017adam}{20}
\bibcite{lane_2018}{21}
\bibcite{divyanshu_2020}{22}
\bibcite{dumoulin2018guide}{23}
\bibcite{ohlberger2015reduced}{24}
\bibcite{NumaKUL}{25}
\ttl@finishall
