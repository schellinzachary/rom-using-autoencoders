\relax 
\providecommand\hyper@newdestlabel[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{JHEP}
\@input{front/title.aux}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\babel@aux{english}{}
\babel@aux{english}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Contents}{i}{chapter*.1}\protected@file@percent }
\@input{chapters/introduction.aux}
\@input{chapters/BGK_model.aux}
\@input{chapters/Deep_Learning.aux}
\@input{chapters/Reduced_order_Modeling.aux}
\@input{chapters/Results.aux}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Hyperparameters for the Fully Connected Autoencoder}{38}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{Ch:ApA}{{A}{38}{Hyperparameters for the Fully Connected Autoencoder}{appendix.A}{}}
\newlabel{Ch:ApA@cref}{{[appendix][1][2147483647]A}{[1][38][]38}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Initial selection for batch size, bottleneck size, number of epochs, learning rate and applied activation functions.\relax }}{38}{table.caption.30}\protected@file@percent }
\newlabel{Tab:First Guess}{{A.1}{38}{Initial selection for batch size, bottleneck size, number of epochs, learning rate and applied activation functions.\relax }{table.caption.30}{}}
\newlabel{Tab:First Guess@cref}{{[table][1][2147483647,1]A.1}{[1][38][]38}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Results for the variation of depth. Given are minimum values of training and validation error as well as the \(\L 2\). The minima where reached around the last 50 epochs of the training.\relax }}{39}{table.caption.31}\protected@file@percent }
\newlabel{Tab:Depth}{{A.2}{39}{Results for the variation of depth. Given are minimum values of training and validation error as well as the \(\L 2\). The minima where reached around the last 50 epochs of the training.\relax }{table.caption.31}{}}
\newlabel{Tab:Depth@cref}{{[table][2][2147483647,1]A.2}{[1][38][]39}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Five experiments over the different depth with $\hy  $ left and $\rare  $ right. The number of layers used for every experiment are given. Training and validation loss are shown over 2000 epochs.\relax }}{40}{figure.caption.32}\protected@file@percent }
\newlabel{Fig:Depth}{{A.1}{40}{Five experiments over the different depth with $\hy $ left and $\rare $ right. The number of layers used for every experiment are given. Training and validation loss are shown over 2000 epochs.\relax }{figure.caption.32}{}}
\newlabel{Fig:Depth@cref}{{[figure][1][2147483647,1]A.1}{[1][39][]40}}
\citation{BGK}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Results for the variation of width. Given is the minimum value of validation error as well as the \(\L 2\). The minima where reached around the last 50 epochs of the training, the \(\L 2\) is evaluated with the model at the last epoch.\relax }}{41}{table.caption.33}\protected@file@percent }
\newlabel{Tab:Width}{{A.3}{41}{Results for the variation of width. Given is the minimum value of validation error as well as the \(\L 2\). The minima where reached around the last 50 epochs of the training, the \(\L 2\) is evaluated with the model at the last epoch.\relax }{table.caption.33}{}}
\newlabel{Tab:Width@cref}{{[table][3][2147483647,1]A.3}{[1][39][]41}}
\@writefile{lot}{\c